{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yupXUk1DKOe"
   },
   "source": [
    "# MNIST from scratch\n",
    "\n",
    "This notebook walks through an example of training a TensorFlow model to do digit classification using the [MNIST data set](http://yann.lecun.com/exdb/mnist/). MNIST is a labeled set of images of handwritten digits.\n",
    "\n",
    "An example follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:20.863031",
     "start_time": "2016-09-16T14:49:20.818734"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "sbUKaF8_uDI_",
    "outputId": "67a51332-3aea-4c29-8c3d-4752db08ccb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import Image\n",
    "import base64\n",
    "Image(data=base64.decodestring(\"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\".encode('utf-8')), embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0QZYD_HuDJF"
   },
   "source": [
    "We're going to be building a model that recognizes these digits as 5, 0, and 4.\n",
    "\n",
    "# Imports and input data\n",
    "\n",
    "We'll proceed in steps, beginning with importing and inspecting the MNIST data. This doesn't have anything to do with TensorFlow in particular -- we're just downloading the data archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:20.958307",
     "start_time": "2016-09-16T14:49:20.864840"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1446749124399,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "w5vKZqr6CDz9",
    "outputId": "794eac6d-a918-4888-e8cf-a8628474d7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "#SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "# for those who have no access to google storage, use lecun's repo please\n",
    "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCtMhpIoC84F"
   },
   "source": [
    "## Working with the images\n",
    "\n",
    "Now we have the files, but the format requires a bit of pre-processing before we can work with it. The data is gzipped, requiring us to decompress it. And, each of the images are grayscale-encoded with values from [0, 255]; we'll normalize these to [-0.5, 0.5].\n",
    "\n",
    "Let's try to unpack the data using the documented format:\n",
    "\n",
    "    [offset] [type]          [value]          [description] \n",
    "    0000     32 bit integer  0x00000803(2051) magic number \n",
    "    0004     32 bit integer  60000            number of images \n",
    "    0008     32 bit integer  28               number of rows \n",
    "    0012     32 bit integer  28               number of columns \n",
    "    0016     unsigned byte   ??               pixel \n",
    "    0017     unsigned byte   ??               pixel \n",
    "    ........ \n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    \n",
    "Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n",
    "We'll start by reading the first image from the test data as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:22.112407",
     "start_time": "2016-09-16T14:49:20.960204"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1446749125010,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "P_3Fm5BpFMDF",
    "outputId": "c8e777e0-d891-4eb1-a178-9809f293cc28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic number 2051\n",
      "image count 10000\n",
      "rows 28\n",
      "columns 28\n",
      "First 10 pixels: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import gzip, binascii, struct, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with gzip.open(test_data_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'image count', 'rows', 'columns']:\n",
    "        # struct.unpack reads the binary data provided by f.read.\n",
    "        # The format string '>i' decodes a big-endian integer, which\n",
    "        # is the encoding of the data.\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "    \n",
    "    # Read the first 28x28 set of pixel values. \n",
    "    # Each pixel is one byte, [0, 255], a uint8.\n",
    "    buf = f.read(28 * 28)\n",
    "    image = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "  \n",
    "    # Print the first few values of image.\n",
    "    print('First 10 pixels:', image[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NXKCQENNRQT"
   },
   "source": [
    "The first 10 pixels are all 0 values. Not very interesting, but also unsurprising. We'd expect most of the pixel values to be the background color, 0.\n",
    "\n",
    "We could print all 28 * 28 values, but what we really need to do to make sure we're reading our data properly is look at an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:22.525418",
     "start_time": "2016-09-16T14:49:22.114324"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1446749126640,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "F_5w-cOoNLaG",
    "outputId": "77dabc81-e3ee-4fcf-ac72-88038494fb6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# We'll show the image and its pixel value histogram side-by-side.\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# To interpret the values as a 28x28 image, we need to reshape\n",
    "# the numpy array, which is one dimensional.\n",
    "ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "ax2.hist(image, bins=20, range=[0,255]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "weVoVR-nN0cN"
   },
   "source": [
    "The large number of 0 values correspond to the background of the image, another large mass of value 255 is black, and a mix of grayscale transition values in between.\n",
    "\n",
    "Both the image and histogram look sensible. But, it's good practice when training image models to normalize values to be centered around 0.\n",
    "\n",
    "We'll do that next. The normalization code is fairly short, and it may be tempting to assume we haven't made mistakes, but we'll double-check by looking at the rendered input and histogram again. Malformed inputs are a surprisingly common source of errors when developing new models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:22.895369",
     "start_time": "2016-09-16T14:49:22.527595"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1446749126656,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "jc1xCZXHNKVp",
    "outputId": "bd45b3dd-438b-41db-ea8f-d202d4a09e63"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's convert the uint8 image to 32 bit floats and rescale \n",
    "# the values to be centered around 0, between [-0.5, 0.5]. \n",
    "# \n",
    "# We again plot the image and histogram to check that we \n",
    "# haven't mangled the data.\n",
    "scaled = image.astype(numpy.float32)\n",
    "scaled = (scaled - (255 / 2.0)) / 255\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(scaled.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.hist(scaled, bins=20, range=[-0.5, 0.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlqlwkX-O0Hd"
   },
   "source": [
    "Great -- we've retained the correct image data while properly rescaling to the range [-0.5, 0.5].\n",
    "\n",
    "## Reading the labels\n",
    "\n",
    "Let's next unpack the test label data. The format here is similar: a magic number followed by a count followed by the labels as `uint8` values. In more detail:\n",
    "\n",
    "    [offset] [type]          [value]          [description] \n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first) \n",
    "    0004     32 bit integer  10000            number of items \n",
    "    0008     unsigned byte   ??               label \n",
    "    0009     unsigned byte   ??               label \n",
    "    ........ \n",
    "    xxxx     unsigned byte   ??               label\n",
    "\n",
    "As with the image data, let's read  the first test set value to sanity check our input path. We'll expect a 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:22.925176",
     "start_time": "2016-09-16T14:49:22.897739"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1446749126903,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "d8zv9yZzQOnV",
    "outputId": "ad203b2c-f095-4035-e0cd-7869c078da3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic number 2049\n",
      "label count 10000\n",
      "First label: 7\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(test_labels_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'label count']:\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "\n",
    "    print('First label:', struct.unpack('B', f.read(1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAGrQSXCQtIm"
   },
   "source": [
    "Indeed, the first label of the test set is 7.\n",
    "\n",
    "## Forming the training, testing, and validation data sets\n",
    "\n",
    "Now that we understand how to read a single element, we can read a much larger set that we'll use for training, testing, and validation.\n",
    "\n",
    "### Image data\n",
    "\n",
    "The code below is a generalization of our prototyping above that reads the entire test and training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:23.525119",
     "start_time": "2016-09-16T14:49:22.928289"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1446749128718,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "ofFZ5oJeRMDA",
    "outputId": "ff2de90b-aed9-4ce5-db8c-9123496186b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  \n",
    "    For MNIST data, the number of channels is always 1.\n",
    "\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and dimensions; we know these values.\n",
    "        bytestream.read(16)\n",
    "\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        return data\n",
    "\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0x4rwXxUR96O"
   },
   "source": [
    "A crucial difference here is how we `reshape` the array of pixel values. Instead of one image that's 28x28, we now have a set of 60,000 images, each one being 28x28. We also include a number of channels, which for grayscale images as we have here is 1.\n",
    "\n",
    "Let's make sure we've got the reshaping parameters right by inspecting the dimensions and the first two images. (Again, mangled input is a very common source of errors.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:23.829853",
     "start_time": "2016-09-16T14:49:23.527283"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1446749129657,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "0AwSo8mlSja_",
    "outputId": "11490c39-7c67-4fe5-982c-ca8278294d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data shape', train_data.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(train_data[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(train_data[1].reshape(28, 28), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwBhQ3ouTQcW"
   },
   "source": [
    "Looks good. Now we know how to index our full set of training and test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBCB9aYxRvBi"
   },
   "source": [
    "### Label data\n",
    "\n",
    "Let's move on to loading the full set of labels. As is typical in classification problems, we'll convert our input labels into a [1-hot](https://en.wikipedia.org/wiki/One-hot) encoding over a length 10 vector corresponding to 10 digits. The vector [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], for example, would correspond to the digit 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:23.854577",
     "start_time": "2016-09-16T14:49:23.831545"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1446749131421,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "9pK1j2WlRwY9",
    "outputId": "1ca31655-e14f-405a-b266-6a6c78827af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 10\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and count; we know these values.\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hb3Vaq72UUxW"
   },
   "source": [
    "As with our image data, we'll double-check that our 1-hot encoding of the first few values matches our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:23.864350",
     "start_time": "2016-09-16T14:49:23.857177"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1446749132853,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "uEBID71nUVj1",
    "outputId": "3f318310-18dd-49ed-9943-47b4aae7ee69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape (60000, 10)\n",
      "First label vector [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Second label vector [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Training labels shape', train_labels.shape)\n",
    "print('First label vector', train_labels[0])\n",
    "print('Second label vector', train_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EwtEhxRUneF"
   },
   "source": [
    "The 1-hot encoding looks reasonable.\n",
    "\n",
    "### Segmenting data into training, test, and validation\n",
    "\n",
    "The final step in preparing our data is to split it into three sets: training, test, and validation. This isn't the format of the original data set, so we'll take a small slice of the training data and treat that as our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:23.874014",
     "start_time": "2016-09-16T14:49:23.866161"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1446749134110,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "e7aBYBtIVxHE",
    "outputId": "bdeae1a8-daff-4743-e594-f1d2229c0f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation shape (5000, 28, 28, 1)\n",
      "Train size 55000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "print('Validation shape', validation_data.shape)\n",
    "print('Train size', train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JFhEH8EVj4O"
   },
   "source": [
    "# Defining the model\n",
    "\n",
    "Now that we've prepared our data, we're ready to define our model.\n",
    "\n",
    "The comments describe the architecture, which fairly typical of models that process image data. The raw input passes through several [convolution](https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer) and [max pooling](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer) layers with [rectified linear](https://en.wikipedia.org/wiki/Convolutional_neural_network#ReLU_layer) activations before several fully connected layers and a [softmax](https://en.wikipedia.org/wiki/Convolutional_neural_network#Loss_layer) loss for predicting the output class. During training, we use [dropout](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout_method).\n",
    "\n",
    "We'll separate our model definition into three steps:\n",
    "\n",
    "1. Defining the variables that will hold the trainable weights.\n",
    "1. Defining the basic model graph structure described above. And,\n",
    "1. Stamping out several copies of the model graph for training, testing, and validation.\n",
    "\n",
    "We'll start with the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:28.803525",
     "start_time": "2016-09-16T14:49:23.875999"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2081,
     "status": "ok",
     "timestamp": 1446749138298,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "Q1VfiAzjzuK8",
    "outputId": "f53a39c9-3a52-47ca-d7a3-9f9d84eccf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# We'll bundle groups of examples during training for efficiency.\n",
    "# This defines the size of the batch.\n",
    "BATCH_SIZE = 60\n",
    "# We have only one channel in our grayscale images.\n",
    "NUM_CHANNELS = 1\n",
    "# The random seed that defines initialization.\n",
    "SEED = 42\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step, which we'll write once we define the graph structure.\n",
    "train_data_node = tf.placeholder(\n",
    "  tf.float32,\n",
    "  shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.float32,\n",
    "                                   shape=(BATCH_SIZE, NUM_LABELS))\n",
    "\n",
    "# For the validation and test data, we'll just hold the entire dataset in\n",
    "# one constant node.\n",
    "validation_data_node = tf.constant(validation_data)\n",
    "test_data_node = tf.constant(test_data)\n",
    "\n",
    "# The variables below hold all the trainable weights. For each, the\n",
    "# parameter defines how the variables will be initialized.\n",
    "conv1_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv1_biases = tf.Variable(tf.zeros([32]))\n",
    "conv2_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, 32, 64],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
    "fc2_weights = tf.Variable(\n",
    "  tf.truncated_normal([512, NUM_LABELS],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHB_u04Z4HO6"
   },
   "source": [
    "Now that we've defined the variables to be trained, we're ready to wire them together into a TensorFlow graph.\n",
    "\n",
    "We'll define a helper to do this, `model`, which will return copies of the graph suitable for training and testing. Note the `train` argument, which controls whether or not dropout is used in the hidden layer. (We want to use dropout only during training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:28.834326",
     "start_time": "2016-09-16T14:49:28.805723"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1446749138306,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "V85_B9QF3uBp",
    "outputId": "457d3e49-73ad-4451-c196-421dd4681efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def model(data, train=False):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "\n",
    "    # Max pooling. The kernel size spec ksize also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "  \n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "\n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bvEtt8C4fLC"
   },
   "source": [
    "Having defined the basic structure of the graph, we're ready to stamp out multiple copies for training, testing, and validation.\n",
    "\n",
    "Here, we'll do some customizations depending on which graph we're constructing. `train_prediction` holds the training graph, for which we use cross-entropy loss and weight regularization. We'll adjust the learning rate during training -- that's handled by the `exponential_decay` operation, which is itself an argument to the `MomentumOptimizer` that performs the actual training.\n",
    "\n",
    "The validation and prediction graphs are much simpler to generate -- we need only create copies of the model with the validation and test inputs and a softmax classifier as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.058141",
     "start_time": "2016-09-16T14:49:28.836169"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1446749139596,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "9pR1EBNT3sCv",
    "outputId": "570681b1-f33e-4618-b742-48e12aa58132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Training computation: logits + cross-entropy loss.\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "  labels=train_labels_node, logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters.\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "# Add the regularization term to the loss.\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.01,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.95,                # Decay rate.\n",
    "  staircase=True)\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                     global_step=batch)\n",
    "\n",
    "# Predictions for the minibatch, validation set and test set.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "# We'll compute them only once in a while by calling their {eval()} method.\n",
    "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
    "test_prediction = tf.nn.softmax(model(test_data_node))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T21uZJq5UfH"
   },
   "source": [
    "# Training and visualizing results\n",
    "\n",
    "Now that we have the training, test, and validation graphs, we're ready to actually go through the training loop and periodically evaluate loss and error.\n",
    "\n",
    "All of these operations take place in the context of a session. In Python, we'd write something like:\n",
    "\n",
    "    with tf.Session() as s:\n",
    "      ...training / test / evaluation loop...\n",
    "  \n",
    "But, here, we'll want to keep the session open so we can poke at values as we work out the details of training. The TensorFlow API includes a function for this, `InteractiveSession`.\n",
    "\n",
    "We'll start by creating a session and initializing the variables we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.357483",
     "start_time": "2016-09-16T14:49:29.059952"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "z6Kc5iql6qxV"
   },
   "outputs": [],
   "source": [
    "# Create a new interactive session that we'll use in\n",
    "# subsequent code cells.\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "# Use our newly created session as the default for \n",
    "# subsequent operations.\n",
    "s.as_default()\n",
    "\n",
    "# Initialize all the variables we defined above.\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcG8H-Ka6_mw"
   },
   "source": [
    "Now we're ready to perform operations on the graph. Let's start with one round of training. We're going to organize our training steps into batches for efficiency; i.e., training using a small set of examples at each step rather than a single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.584699",
     "start_time": "2016-09-16T14:49:29.359107"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1446749389138,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "LYVxeEox71Pg",
    "outputId": "9184b5df-009a-4b1b-e312-5be94351351f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 60\n",
    "\n",
    "# Grab the first BATCH_SIZE examples and labels.\n",
    "batch_data = train_data[:BATCH_SIZE, :, :, :]\n",
    "batch_labels = train_labels[:BATCH_SIZE]\n",
    "\n",
    "# This dictionary maps the batch data (as a numpy array) to the\n",
    "# node in the graph it should be fed to.\n",
    "feed_dict = {train_data_node: batch_data,\n",
    "             train_labels_node: batch_labels}\n",
    "\n",
    "# Run the graph and fetch some of the nodes.\n",
    "_, l, lr, predictions = s.run(\n",
    "  [optimizer, loss, learning_rate, train_prediction],\n",
    "  feed_dict=feed_dict)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bL4-RNm_K-B"
   },
   "source": [
    "Let's take a look at the predictions. How did we do? Recall that the output will be probabilities over the possible classes, so let's look at those probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.593985",
     "start_time": "2016-09-16T14:49:29.586233"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1446749519023,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "2eNitV_4_ZUL",
    "outputId": "f1340dd1-255b-4523-bf62-7e3ebb361333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2539274e-04 4.7622081e-05 1.6686796e-03 5.6782628e-05 6.0343140e-01\n",
      " 4.3496966e-02 2.1931670e-05 1.4128619e-04 1.5490306e-05 3.5089436e-01]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5MgraJb_eQZ"
   },
   "source": [
    "As expected without training, the predictions are all noise. Let's write a scoring function that picks the class with the maximum probability and compares with the example's label. We'll start by converting the probability vectors returned by the softmax into predictions we can match against the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.606284",
     "start_time": "2016-09-16T14:49:29.597095"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1446750411574,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "wMMlUf5rCKgT",
    "outputId": "2c10e96d-52b6-47b0-b6eb-969ad462d46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prediction 4\n",
      "(60, 10)\n",
      "All predictions [4 4 2 7 7 7 7 7 7 7 7 7 0 8 9 0 7 7 0 7 4 0 5 0 9 9 7 0 7 4 7 7 7 0 7 7 9\n",
      " 7 9 9 0 7 7 7 2 7 0 7 2 9 9 9 9 9 0 7 9 4 8 7]\n"
     ]
    }
   ],
   "source": [
    "# The highest probability in the first entry.\n",
    "print('First prediction', numpy.argmax(predictions[0]))\n",
    "\n",
    "# But, predictions is actually a list of BATCH_SIZE probability vectors.\n",
    "print(predictions.shape)\n",
    "\n",
    "# So, we'll take the highest probability for each vector.\n",
    "print('All predictions', numpy.argmax(predictions, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pMCIZ3_C2ni"
   },
   "source": [
    "Next, we can do the same thing for our labels -- using `argmax` to convert our 1-hot encoding into a digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.615484",
     "start_time": "2016-09-16T14:49:29.609168"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1446750498351,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "kZWp4T0JDDUe",
    "outputId": "47b588cd-bc82-45c3-a5d0-8d84dc27a3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch labels [7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0 1 6 7 1 9 7 6 5 5 8 8 3 4 4 8 7 3\n",
      " 6 4 6 6 3 8 8 9 9 4 4 0 7 8 1 0 0 1 8 5 7 1 7]\n"
     ]
    }
   ],
   "source": [
    "print('Batch labels', numpy.argmax(batch_labels, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bi5Z6whtDiht"
   },
   "source": [
    "Now we can compare the predicted and label classes to compute the error rate and confusion matrix for this batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.841313",
     "start_time": "2016-09-16T14:49:29.618274"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1446751307304,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "U4hrLW4CDtQB",
    "outputId": "720494a3-cbf9-4687-9d94-e64a33fdd78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(batch_labels, 1))\n",
    "total = predictions.shape[0]\n",
    "\n",
    "print(float(correct) / float(total))\n",
    "\n",
    "confusions = numpy.zeros([10, 10], numpy.float32)\n",
    "bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(batch_labels, 1))\n",
    "for predicted, actual in bundled:\n",
    "  confusions[predicted, actual] += 1\n",
    "\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZmx_9DiDXQ3"
   },
   "source": [
    "Now let's wrap this up into our scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:49:29.857607",
     "start_time": "2016-09-16T14:49:29.843904"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1446751995007,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "DPJie7bPDaLa",
    "outputId": "a06c64ed-f95f-416f-a621-44cccdaba0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate and confusions.\"\"\"\n",
    "    correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    error = 100.0 - (100 * float(correct) / float(total))\n",
    "\n",
    "    confusions = numpy.zeros([10, 10], numpy.float32)\n",
    "    bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))\n",
    "    for predicted, actual in bundled:\n",
    "        confusions[predicted, actual] += 1\n",
    "    \n",
    "    return error, confusions\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLv22cjeB5Rd"
   },
   "source": [
    "We'll need to train for some time to actually see useful predicted values. Let's define a loop that will go through our data. We'll print the loss and error periodically.\n",
    "\n",
    "Here, we want to iterate over the entire data set rather than just the first batch, so we'll need to slice the data to that end.\n",
    "\n",
    "(One pass through our training set will take some time on a CPU, so be patient if you are executing this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:53:26.998313",
     "start_time": "2016-09-16T14:49:29.860079"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4cgKJrS1_vej"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 of 916\n",
      "Mini-batch loss: 7.71255 Error: 91.66667 Learning rate: 0.01000\n",
      "Validation error: 88.9%\n",
      "Step 100 of 916\n",
      "Mini-batch loss: 3.29426 Error: 8.33333 Learning rate: 0.01000\n",
      "Validation error: 6.6%\n",
      "Step 200 of 916\n",
      "Mini-batch loss: 3.30870 Error: 8.33333 Learning rate: 0.01000\n",
      "Validation error: 3.5%\n",
      "Step 300 of 916\n",
      "Mini-batch loss: 3.17898 Error: 5.00000 Learning rate: 0.01000\n",
      "Validation error: 3.2%\n",
      "Step 400 of 916\n",
      "Mini-batch loss: 3.12883 Error: 5.00000 Learning rate: 0.01000\n",
      "Validation error: 2.6%\n",
      "Step 500 of 916\n",
      "Mini-batch loss: 3.01946 Error: 1.66667 Learning rate: 0.01000\n",
      "Validation error: 2.3%\n",
      "Step 600 of 916\n",
      "Mini-batch loss: 3.03429 Error: 3.33333 Learning rate: 0.01000\n",
      "Validation error: 2.0%\n",
      "Step 700 of 916\n",
      "Mini-batch loss: 3.24609 Error: 10.00000 Learning rate: 0.01000\n",
      "Validation error: 2.0%\n",
      "Step 800 of 916\n",
      "Mini-batch loss: 3.01046 Error: 5.00000 Learning rate: 0.01000\n",
      "Validation error: 1.7%\n",
      "Step 900 of 916\n",
      "Mini-batch loss: 2.85113 Error: 0.00000 Learning rate: 0.01000\n",
      "Validation error: 1.8%\n"
     ]
    }
   ],
   "source": [
    "# Train over the first 1/4th of our training set.\n",
    "steps = train_size // BATCH_SIZE\n",
    "for step in range(steps):\n",
    "    # Compute the offset of the current minibatch in the data.\n",
    "    # Note that we could use better randomization across epochs.\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    # This dictionary maps the batch data (as a numpy array) to the\n",
    "    # node in the graph it should be fed to.\n",
    "    feed_dict = {train_data_node: batch_data,\n",
    "                 train_labels_node: batch_labels}\n",
    "    # Run the graph and fetch some of the nodes.\n",
    "    _, l, lr, predictions = s.run(\n",
    "      [optimizer, loss, learning_rate, train_prediction],\n",
    "      feed_dict=feed_dict)\n",
    "    \n",
    "    # Print out the loss periodically.\n",
    "    if step % 100 == 0:\n",
    "        error, _ = error_rate(predictions, batch_labels)\n",
    "        print('Step %d of %d' % (step, steps))\n",
    "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
    "        print('Validation error: %.1f%%' % error_rate(\n",
    "              validation_prediction.eval(), validation_labels)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4LskgGXIDAm"
   },
   "source": [
    "The error seems to have gone down. Let's evaluate the results using the test set.\n",
    "\n",
    "To help identify rare mispredictions, we'll include the raw count of each (prediction, label) pair in the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:55:10.942063",
     "start_time": "2016-09-16T14:53:26.999971"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1446752934104,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "6Yh1jGFuIKc_",
    "outputId": "4e411de4-0fe2-451b-e4ca-8a4854f0db89"
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D_4 (defined at <ipython-input-13-aaecf3fe07dc>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Softmax_2/_27}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'Conv2D_4', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1017, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-0548c76f0f81>\", line 31, in <module>\n    test_prediction = tf.nn.softmax(model(test_data_node))\n  File \"<ipython-input-13-aaecf3fe07dc>\", line 9, in model\n    padding='SAME')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1006, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3303, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1799, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D_4 (defined at <ipython-input-13-aaecf3fe07dc>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Softmax_2/_27}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d8e761a76c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test error: %.1f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \"\"\"\n\u001b[0;32m--> 722\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5186\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5187\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5188\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D_4 (defined at <ipython-input-13-aaecf3fe07dc>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Softmax_2/_27}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'Conv2D_4', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1017, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-0548c76f0f81>\", line 31, in <module>\n    test_prediction = tf.nn.softmax(model(test_data_node))\n  File \"<ipython-input-13-aaecf3fe07dc>\", line 9, in model\n    padding='SAME')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1006, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3303, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1799, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D_4 (defined at <ipython-input-13-aaecf3fe07dc>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Softmax_2/_27}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "test_error, confusions = error_rate(test_prediction.eval(), test_labels)\n",
    "print('Test error: %.1f%%' % test_error)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
    "\n",
    "for i, cas in enumerate(confusions):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLnS4dGiMwI1"
   },
   "source": [
    "We can see here that we're mostly accurate, with some errors you might expect, e.g., '9' is often confused as '4'.\n",
    "\n",
    "Let's do another sanity check to make sure this matches roughly the distribution of our test set, e.g., it seems like we have fewer '5' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-16T14:55:18.083458",
     "start_time": "2016-09-16T14:55:17.830485"
    },
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1446753006584,
     "user": {
      "color": "#1FA15D",
      "displayName": "Michael Piatek",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "00327059602783983041",
      "photoUrl": "//lh6.googleusercontent.com/-wKJwK_OPl34/AAAAAAAAAAI/AAAAAAAAAlk/Rh3u6O2Z7ns/s50-c-k-no/photo.jpg",
      "sessionId": "716a6ad5e180d821",
      "userId": "106975671469698476657"
     },
     "user_tz": 480
    },
    "id": "x5KOv1AJMgzV",
    "outputId": "2acdf737-bab6-408f-8b3c-05fa66d04fe6"
   },
   "outputs": [],
   "source": [
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.hist(numpy.argmax(test_labels, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6DzLSK5M1ju"
   },
   "source": [
    "Indeed, we appear to have fewer 5 labels in the test set. So, on the whole, it seems like our model is learning and our early results are sensible.\n",
    "\n",
    "But, we've only done one round of training. We can greatly improve accuracy by training for longer. To try this out, just re-execute the training cell above."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
